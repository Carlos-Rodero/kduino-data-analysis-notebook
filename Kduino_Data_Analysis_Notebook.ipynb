{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kduino_Data_Analysis_Notebook.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carlos-Rodero/kduino_data_analysis_notebook/blob/main/Kduino_Data_Analysis_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mooda===2.0.0\n",
        "\n",
        "import mooda as md\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import yaml\n",
        "import os\n",
        "import re\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import matplotlib.dates as mdates\n",
        "from scipy import stats, interpolate\n",
        "from io import StringIO\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "from google.colab import files\n",
        "\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "id": "K3rLLm5pruii",
        "outputId": "757405fa-c9c8-4ccb-9a13-cae3b870b274",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mooda===2.0.0 in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: elasticsearch>=7.8.0 in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (8.17.1)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (3.1.0)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (3.10.0)\n",
            "Requirement already satisfied: netCDF4>=1.5.3 in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (1.7.2)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (2.2.2)\n",
            "Requirement already satisfied: plotly>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (5.24.1)\n",
            "Requirement already satisfied: scikit-learn>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (1.13.1)\n",
            "Requirement already satisfied: xarray>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (2025.1.2)\n",
            "Requirement already satisfied: nbformat>=5.0.7 in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (5.10.4)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (2.32.3)\n",
            "Requirement already satisfied: ipywidgets>=7.6.3 in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (7.7.1)\n",
            "Requirement already satisfied: gsw in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (3.6.19)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (0.14.4)\n",
            "Requirement already satisfied: stockstats in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (0.6.4)\n",
            "Requirement already satisfied: erddap-python in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (1.0.0)\n",
            "Requirement already satisfied: h5netcdf>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from mooda===2.0.0) (1.5.0)\n",
            "Requirement already satisfied: elastic-transport<9,>=8.15.1 in /usr/local/lib/python3.11/dist-packages (from elasticsearch>=7.8.0->mooda===2.0.0) (8.17.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->mooda===2.0.0) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->mooda===2.0.0) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->mooda===2.0.0) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->mooda===2.0.0) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->mooda===2.0.0) (1.9.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from h5netcdf>=0.8.0->mooda===2.0.0) (3.12.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from h5netcdf>=0.8.0->mooda===2.0.0) (24.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.3->mooda===2.0.0) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.3->mooda===2.0.0) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.3->mooda===2.0.0) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.3->mooda===2.0.0) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.3->mooda===2.0.0) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets>=7.6.3->mooda===2.0.0) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->mooda===2.0.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->mooda===2.0.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->mooda===2.0.0) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->mooda===2.0.0) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->mooda===2.0.0) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->mooda===2.0.0) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->mooda===2.0.0) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.0.7->mooda===2.0.0) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.0.7->mooda===2.0.0) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.0.7->mooda===2.0.0) (5.7.2)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.11/dist-packages (from netCDF4>=1.5.3->mooda===2.0.0) (1.6.4.post1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4>=1.5.3->mooda===2.0.0) (2025.1.31)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->mooda===2.0.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->mooda===2.0.0) (2025.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.9.0->mooda===2.0.0) (9.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->mooda===2.0.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->mooda===2.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.24.0->mooda===2.0.0) (2.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.23.1->mooda===2.0.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.23.1->mooda===2.0.0) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->mooda===2.0.0) (1.0.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.3->mooda===2.0.0) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.3->mooda===2.0.0) (6.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.3->mooda===2.0.0) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.3->mooda===2.0.0) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.3->mooda===2.0.0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.3->mooda===2.0.0) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.3->mooda===2.0.0) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.3->mooda===2.0.0) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.3->mooda===2.0.0) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.3->mooda===2.0.0) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.3->mooda===2.0.0) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=1.1.2->mooda===2.0.0) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.0.7->mooda===2.0.0) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.0.7->mooda===2.0.0) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.0.7->mooda===2.0.0) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.0.7->mooda===2.0.0) (0.22.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.0.7->mooda===2.0.0) (4.3.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->mooda===2.0.0) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.6.3->mooda===2.0.0) (0.8.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (23.1.0)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (7.16.6)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (1.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.6.3->mooda===2.0.0) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.6.3->mooda===2.0.0) (0.2.13)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat>=5.0.7->mooda===2.0.0) (4.12.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (3.1.1)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (1.4.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.3->mooda===2.0.0) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><img alt=\"logo\" height=\"150px\" src='https://drive.google.com/uc?export=view&id=11Swg70eHalalGMv8HemoK6l7qu3XRuLC' align=\"center\" hspace=\"10px\" vspace=\"0px\"/></p>\n",
        "<h1><b>KdUINO Data Analysis Notebook</b></h1>\n",
        "\n",
        "The KdUINO Data Analysis Notebook is a Jupyter Notebook hosted by Google Colab designed to analyze data files from [KdUINO](https://monocle-h2020.eu/Sensors_and_services/KdUINO) instrumentation. Also, provide methods to generate plots and convert data files in netCDF and CSV format.</br>This Notebook works with different versions of KdUINO:\n",
        "*   KduPRO\n",
        "*   KduSTICK\n",
        "*   KduMOD Professional\n",
        "*   KduMOD Low-Cost\n",
        "</br>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Jpl8roRLyuGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><img alt=\"logo\" height=\"100px\" src='https://git.csic.es/36579996Z/kduino-data-analysis/-/raw/master/docs/img_docs/logo.png' align=\"center\" hspace=\"10px\" vspace=\"0px\"/></p>\n",
        "\n",
        "This project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 776480 ([MONOCLE](https://monocle-h2020.eu/))."
      ],
      "metadata": {
        "id": "XoBxBDf03N3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select KdUINO\n",
        "Please select your KdUINO instrument:"
      ],
      "metadata": {
        "id": "Ehyjv3wj3WvT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-_0-Zb11SgY_"
      },
      "outputs": [],
      "source": [
        "#@title Select KdUINO { run: \"auto\", display-mode: \"form\" }\n",
        "kduino = \"KduPRO\" #@param [\"KduPRO\", \"KduSTICK\", \"KduMOD Professional\", \"KduMOD Low-Cost\", \"KdUINO\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload Files\n",
        "\n",
        "Please upload the files from your KdUINO instrument:"
      ],
      "metadata": {
        "id": "TTqxEYUKvSup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "UFbx8zivrpGh",
        "outputId": "3748d64b-79cc-497c-9ba4-8e4a65aff8d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-caba0553-c481-4d25-b498-273ac7778533\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-caba0553-c481-4d25-b498-273ac7778533\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2025-02-05_buoyBuoy01_Spain_Somorrostro_3.50.txt to 2025-02-05_buoyBuoy01_Spain_Somorrostro_3.50 (3).txt\n",
            "Saving 2025-02-05_buoyBuoy01_Spain_Somorrostro_2.80.txt to 2025-02-05_buoyBuoy01_Spain_Somorrostro_2.80 (3).txt\n",
            "Saving 2025-02-05_buoyBuoy01_Spain_Somorrostro_2.10.txt to 2025-02-05_buoyBuoy01_Spain_Somorrostro_2.10 (3).txt\n",
            "Saving 2025-02-05_buoyBuoy01_Spain_Somorrostro_1.40.txt to 2025-02-05_buoyBuoy01_Spain_Somorrostro_1.40 (3).txt\n",
            "Saving 2005-07-14_buoyBuoy01_Spain_Somorrostro_0.70.txt to 2005-07-14_buoyBuoy01_Spain_Somorrostro_0.70 (3).txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration\n",
        "\n",
        "Please configure the time of the sample."
      ],
      "metadata": {
        "id": "Ky56SgiBHnK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configuration start and stop { run: \"auto\", display-mode: \"form\" }\n",
        "\n",
        "date_start = '2025-02-05' #@param {type:\"date\"}\n",
        "time_start = '15:00:00' #@param {type:\"string\"}\n",
        "date_stop = '2025-02-05' #@param {type:\"date\"}\n",
        "time_stop = '15:30:00' #@param {type:\"string\"}\n",
        "\n",
        "pre_datetime_start = date_start + \"Z\" + time_start + \"T+00:00\"\n",
        "pre_datetime_stop = date_stop + \"Z\" + time_stop + \"T+00:00\"\n",
        "\n",
        "datetime_start = datetime.fromisoformat(pre_datetime_start)\n",
        "datetime_stop = datetime.fromisoformat(pre_datetime_stop)"
      ],
      "metadata": {
        "id": "BEu3hNftIqLx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set r2 value\n",
        "\n",
        "Please configure the r2 value as a Quality Control value (between 0.0 and 1.0)\n",
        "\n"
      ],
      "metadata": {
        "id": "vuM9Q-43C0L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select r2 value { run: \"auto\", display-mode: \"form\" }\n",
        "r2_value_input = 0.0 # @param {\"type\":\"number\"}\n"
      ],
      "metadata": {
        "id": "O16qBc1oDMwr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis\n",
        "\n",
        "Analysis of the KdUINO instrument.\n",
        "\n",
        "1.- Analysis and output as .csv file\n",
        "\n",
        "2.- Plot linear regressions for each minute (in the PAR band)\n",
        "\n",
        "3.- Plot Kd Red, Green, Blue and PAR with r2 parameter"
      ],
      "metadata": {
        "id": "res-K0XUOUNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.- Analysis and output as .csv file\n",
        "\n",
        "def analysis_kduino():\n",
        "  # Function to analyse data from KdUINO to obtain Kd\n",
        "  if kduino == 'KduPRO':\n",
        "    print(\"KduPRO\")\n",
        "    print(datetime_start)\n",
        "    print(datetime_stop)\n",
        "\n",
        "    # Definitions for regular expression paterns\n",
        "    start_string_metadata = r\"METADATA\"\n",
        "    stop_string_metadata = r\"DATA\"\n",
        "    # start_string_data = r\"\\bDATA\"\n",
        "    # stop_string_data = r\"METADATA\"\n",
        "    last_start_string_data = r\"\\bDATA\"\n",
        "    end_string_data = r'$(?![\\r\\n])'\n",
        "\n",
        "    metadata_patron = re.compile(r'{}(?P<length>)\\s*(?P<table>[\\s\\S]*?){}'.format(\n",
        "        start_string_metadata, stop_string_metadata))\n",
        "    data_patron = re.compile(r'{}(?P<length>)\\s*(?P<table>[\\s\\S]*?){}'.format(\n",
        "        last_start_string_data, end_string_data))\n",
        "\n",
        "    selected_info = \"\"\n",
        "    metadata_list = []\n",
        "    metadata = {}\n",
        "    data_list = []\n",
        "    kdupro_list = []\n",
        "\n",
        "    for k, v in uploaded.items():\n",
        "      with open(k) as reader:\n",
        "        content = reader.read()\n",
        "\n",
        "        # Regular expression to find the metadata patron\n",
        "        for m in re.finditer(metadata_patron, content):\n",
        "          selected_info = m.group('table')\n",
        "          lines = selected_info.splitlines()\n",
        "\n",
        "          for line in lines:\n",
        "            key = line.split(\":\")[0]\n",
        "            if line.count(\":\") > 1:\n",
        "              date_splitted = (line.rsplit(\":\")[-3:])\n",
        "              date_splitted = \" \".join(date_splitted)\n",
        "              value = date_splitted\n",
        "              metadata[key] = value\n",
        "            else:\n",
        "              try:\n",
        "                value = line.split(\":\")[1]\n",
        "                metadata[key] = value.strip()\n",
        "              except IndexError as er:\n",
        "                pass\n",
        "\n",
        "          metadata_list.append(metadata)\n",
        "\n",
        "        # Regular expression to find the data patron\n",
        "        for d in re.finditer(data_patron, content):\n",
        "          selected_info_data = d.group('table')\n",
        "          data = StringIO(selected_info_data)\n",
        "\n",
        "          df = pd.read_csv(data, skipinitialspace=True, skiprows=1, header=None,\n",
        "                           parse_dates={'TIME': [0]},\n",
        "                           delimiter=' ', engine='python').set_index('TIME')\n",
        "\n",
        "          data_list.append(df)\n",
        "\n",
        "    for index, df in enumerate(data_list):\n",
        "      if datetime_start in df.index or datetime_stop in df.index:\n",
        "        kdupro_list.append(index)\n",
        "\n",
        "    # process the files we have selected\n",
        "    def create_wf():\n",
        "      df = data_list[index]\n",
        "      metadata = metadata_list[index]\n",
        "      df.columns = range(df.shape[1])\n",
        "\n",
        "      # Delete unused columns\n",
        "      if len(df.columns) > 4:\n",
        "        df_copy = df.copy()\n",
        "        ncol = len(df.columns)\n",
        "        x = range(4, ncol)\n",
        "        df = df.drop(x, axis=1)\n",
        "\n",
        "      df.columns = range(df.shape[1])\n",
        "\n",
        "      # Creation of WaterFrame\n",
        "      wf = md.WaterFrame()\n",
        "\n",
        "      # Copy metadata to waterframe\n",
        "      wf.metadata = metadata\n",
        "      depth = wf.metadata[\"depth\"]\n",
        "\n",
        "      # Set name of parameters\n",
        "      param_red = f'RED_{depth}'\n",
        "      param_green = f'GREEN_{depth}'\n",
        "      param_blue = f'BLUE_{depth}'\n",
        "      param_clear = f'CLEAR_{depth}'\n",
        "\n",
        "      # Set name of QC parameters\n",
        "      param_red_qc = f'RED_{depth}_QC'\n",
        "      param_green_qc = f'GREEN_{depth}_QC'\n",
        "      param_blue_qc = f'BLUE_{depth}_QC'\n",
        "      param_clear_qc = f'CLEAR_{depth}_QC'\n",
        "\n",
        "      # Init data of waterframe\n",
        "      wf.data[param_red] = df[0]\n",
        "      wf.data[param_green] = df[1]\n",
        "      wf.data[param_blue] = df[2]\n",
        "      wf.data[param_clear] = df[3]\n",
        "\n",
        "      # Create vocabulary\n",
        "      wf.vocabulary[param_red] = {'units': \"counts\"}\n",
        "      wf.vocabulary[param_green] = {'units': \"counts\"}\n",
        "      wf.vocabulary[param_blue] = {'units': \"counts\"}\n",
        "      wf.vocabulary[param_clear] = {'units': \"counts\"}\n",
        "\n",
        "      # Resample to seconds\n",
        "      wf.resample('s')\n",
        "\n",
        "      # Delete last index because it is a minute that we are not going to use\n",
        "      wf.data.drop(wf.data.tail(1).index, inplace=True)\n",
        "\n",
        "      # Extract data of the dataframe df. Put all counts in the proper column\n",
        "      red_list = []\n",
        "      green_list = []\n",
        "      blue_list = []\n",
        "      clear_list = []\n",
        "\n",
        "      for j in range(len(df_copy.index)-1):\n",
        "        for i in range(len(df_copy.columns)):\n",
        "          if i % 4 == 0:\n",
        "            red_list.append(df_copy[i][j])\n",
        "            green_list.append(df_copy[i+1].iloc[j])\n",
        "            blue_list.append(df_copy[i+2].iloc[j])\n",
        "            clear_list.append(df_copy[i+3].iloc[j])\n",
        "      red_array = np.array(red_list)\n",
        "      green_array = np.array(green_list)\n",
        "      blue_array = np.array(blue_list)\n",
        "      clear_array = np.array(clear_list)\n",
        "\n",
        "      wf.data[param_red] = red_array\n",
        "      wf.data[param_green] = green_array\n",
        "      wf.data[param_blue] = blue_array\n",
        "      wf.data[param_clear] = clear_array\n",
        "\n",
        "      # Init waterframe QC data\n",
        "      wf.data[param_red_qc] = 0\n",
        "      wf.data[param_green_qc] = 0\n",
        "      wf.data[param_blue_qc] = 0\n",
        "      wf.data[param_clear_qc] = 0\n",
        "\n",
        "      return wf\n",
        "\n",
        "    def merge_metadata(dict1, dict2):\n",
        "      # Merge dictionaries\n",
        "      dict3 = {**dict1, **dict2}\n",
        "      # Iterate over items in new dictionary\n",
        "      for key, value in dict3.items():\n",
        "        # If keys are in both dictionaries\n",
        "        if key in dict1 and key in dict2:\n",
        "          # If dictionary contains list of elements\n",
        "          if isinstance(value, list):\n",
        "            # If values of new dict and values from parameter dict are different,\n",
        "            # and not included in the new dict\n",
        "            if (dict1[key] not in value) and (set(dict1[key]) != set(value)):\n",
        "              dict3[key].append(dict1[key])\n",
        "            elif (dict2[key] not in value) and (set(dict2[key]) != set(value)):\n",
        "              dict3[key].append(dict2[key])\n",
        "\n",
        "        # If dictionary not contains list of elements\n",
        "        else:\n",
        "          if value != dict1[key]:\n",
        "            dict3[key] = [value, dict1[key]]\n",
        "          elif value != dict2[key]:\n",
        "            dict3[key] = [value, dict2[key]]\n",
        "\n",
        "        return dict3\n",
        "\n",
        "    wf_list = []\n",
        "    for index in kdupro_list:\n",
        "      wf = create_wf()\n",
        "      wf_list.append(wf)\n",
        "\n",
        "    # Declare lists\n",
        "    names = []\n",
        "    depths = []\n",
        "\n",
        "    # Create unique waterframe\n",
        "    wf_all = md.WaterFrame()\n",
        "\n",
        "    # Concat all waterframes\n",
        "    for index, wf in enumerate(wf_list):\n",
        "      if index == 0:\n",
        "        wf_all = wf.copy()\n",
        "      else:\n",
        "        # Concat data\n",
        "        wf_all.data = pd.concat([wf_all.data, wf.data], axis=1)\n",
        "        # Add metadata\n",
        "        wf_all.metadata = merge_metadata(wf.metadata, wf_all.metadata)\n",
        "        # Add vocabulary\n",
        "        for param in wf.parameters:\n",
        "          wf_all.vocabulary[param] = wf.vocabulary[param]\n",
        "\n",
        "    # Append names and depths to each list\n",
        "    for wf in wf_list:\n",
        "      if wf is None:\n",
        "        pass\n",
        "      else:\n",
        "        name = wf.metadata[\"name\"]\n",
        "        names.append(name)\n",
        "        depth = wf.metadata[\"depth\"]\n",
        "        depths.append(depth)\n",
        "\n",
        "    # Slice time\n",
        "    mask = (\n",
        "        wf_all.data.index >= datetime_start) & (\n",
        "            wf_all.data.index <= datetime_stop)\n",
        "    wf_all.data = wf_all.data.loc[mask]\n",
        "\n",
        "    # Resample time\n",
        "    wf_all.resample(\"T\")\n",
        "\n",
        "    # Convert depths list elements to float, and save it as a numpy array\n",
        "    depths = np.array(list(map(float, depths)))\n",
        "\n",
        "    # Save CLEAR data in one new waterframe\n",
        "    wf_clear = md.WaterFrame()\n",
        "    wf_clear.metadata = wf_all.metadata\n",
        "    wf_clear.vocabulary = wf_all.vocabulary\n",
        "    match_CLEAR = [s for s in wf_all.data if (\"CLEAR_\" in s) and (\"QC\" not in s)]\n",
        "    print(match_CLEAR)\n",
        "    # to solve error\n",
        "    wf_clear.data = wf_all.data.filter(match_CLEAR)\n",
        "\n",
        "    # Create columns Kd and R2\n",
        "    wf_all.vocabulary = {}\n",
        "    create_columns_Kd(wf_all)\n",
        "\n",
        "    # Create lists with parameters name\n",
        "    # match_CLEAR = [s for s in wf_all.data if (\"CLEAR_\" in s) and (\"QC\" not in s)]\n",
        "    match_RED = [s for s in wf_all.data if (\"RED_\" in s) and (\"QC\" not in s)]\n",
        "    match_GREEN = [s for s in wf_all.data if (\"GREEN_\" in s) and (\"QC\" not in s)]\n",
        "    match_BLUE = [s for s in wf_all.data if (\"BLUE_\" in s) and (\"QC\" not in s)]\n",
        "\n",
        "    # Iterate over each row of data\n",
        "    for index, _row in wf_all.data.iterrows():\n",
        "      # Call function to calculate Kd\n",
        "      # CLEAR\n",
        "      calculate_kd(\n",
        "          wf_all, match_CLEAR, index, depths, column_name_Kd='KD_CLEAR', column_name_R2='R2_CLEAR')\n",
        "      # RED\n",
        "      calculate_kd(\n",
        "          wf_all, match_RED, index, depths, column_name_Kd='KD_RED', column_name_R2='R2_RED')\n",
        "      # GREEN\n",
        "      calculate_kd(\n",
        "          wf_all, match_GREEN, index, depths, column_name_Kd='KD_GREEN', column_name_R2='R2_GREEN')\n",
        "      # BLUE\n",
        "      calculate_kd(\n",
        "          wf_all, match_BLUE, index, depths, column_name_Kd='KD_BLUE', column_name_R2='R2_BLUE')\n",
        "\n",
        "    print(\"\\nAnalysis finished\")\n",
        "\n",
        "  else:\n",
        "    print(\"KdUINO instrument not configured well.\")\n",
        "\n",
        "  return wf_clear, wf_all, depths\n",
        "\n",
        "\n",
        "def create_columns_Kd(wf):\n",
        "  \"\"\"\n",
        "  Create parameters in WaterFrame\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "      wf: Mooda waterframe object\n",
        "          Waterframe with data\n",
        "\n",
        "  \"\"\"\n",
        "  wf.data['KD_CLEAR'] = np.nan\n",
        "  wf.vocabulary['KD_CLEAR'] = {'units': \"1/m\",\n",
        "                                'long_name': \"diffuse attenuation coefficient\"}\n",
        "  wf.data['KD_CLEAR_QC'] = 0\n",
        "  wf.data['KD_RED'] = np.nan\n",
        "  wf.vocabulary['KD_RED'] = {'units': \"1/m\",\n",
        "                              'long_name': \"diffuse attenuation coefficient\"}\n",
        "  wf.data['KD_RED_QC'] = 0\n",
        "  wf.data['KD_GREEN'] = np.nan\n",
        "  wf.vocabulary['KD_GREEN'] = {'units': \"1/m\",\n",
        "                                'long_name': \"diffuse attenuation coefficient\"}\n",
        "  wf.data['KD_GREEN_QC'] = 0\n",
        "  wf.data['KD_BLUE'] = np.nan\n",
        "  wf.vocabulary['KD_BLUE'] = {'units': \"1/m\",\n",
        "                              'long_name': \"diffuse attenuation coefficient\"}\n",
        "  wf.data['KD_BLUE_QC'] = 0\n",
        "  wf.data['R2_CLEAR'] = np.nan\n",
        "  wf.vocabulary['R2_CLEAR'] = {'units': \"None\",\n",
        "                                'long_name': \"coefficient of determination\"}\n",
        "  wf.data['R2_CLEAR_QC'] = 0\n",
        "  wf.data['R2_RED'] = np.nan\n",
        "  wf.vocabulary['R2_RED'] = {'units': \"None\",\n",
        "                              'long_name': \"coefficient of determination\"}\n",
        "  wf.data['R2_RED_QC'] = 0\n",
        "  wf.data['R2_GREEN'] = np.nan\n",
        "  wf.vocabulary['R2_GREEN'] = {'units': \"None\",\n",
        "                                'long_name': \"coefficient of determination\"}\n",
        "  wf.data['R2_GREEN_QC'] = 0\n",
        "  wf.data['R2_BLUE'] = np.nan\n",
        "  wf.vocabulary['R2_BLUE'] = {'units': \"None\",\n",
        "                              'long_name': \"coefficient of determination\"}\n",
        "  wf.data['R2_BLUE_QC'] = 0\n",
        "\n",
        "\n",
        "def calculate_kd(wf, match, index, depths, column_name_Kd, column_name_R2):\n",
        "  \"\"\"\n",
        "  Calculate Kd and R2 from waterframe data\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "      wf: Mooda waterframe object\n",
        "          Waterframe with data\n",
        "\n",
        "      match: list\n",
        "          Lists with parameters name\n",
        "\n",
        "      index: Pandas Timestamp\n",
        "          The index of the row\n",
        "\n",
        "      depths: numpy array\n",
        "          Array with depths needed to calculate Kd\n",
        "\n",
        "      column_name_Kd: str\n",
        "          Name of Kd column\n",
        "\n",
        "      column_name_R2: str\n",
        "          Name of R2 column\n",
        "\n",
        "  \"\"\"\n",
        "  # Get elements of row\n",
        "  row = wf.data.loc[index, match].tolist()\n",
        "\n",
        "  # Calulate log of values\n",
        "  with np.errstate(divide='ignore'):\n",
        "      row = np.log(row)\n",
        "  # Get indices where element is Nan or Infinite\n",
        "  indices = [i for i, s in enumerate(row) if np.isnan(s) or np.isinf(s)]\n",
        "\n",
        "  # Delete null elements from lists\n",
        "  row = np.delete(row, indices).tolist()\n",
        "  depths_row = np.delete(depths, indices).tolist()\n",
        "\n",
        "  # Calculate Kd from linear regression\n",
        "  try:\n",
        "    slope, intercept, r_value, _p_value, _std_err = stats.linregress(\n",
        "        depths_row, row)\n",
        "\n",
        "    if r2_value_input is not None:\n",
        "        if r_value**2 >= r2_value_input:\n",
        "            wf.data.at[index, column_name_Kd] = slope * (-1)\n",
        "            wf.data.at[index, column_name_R2] = r_value**2\n",
        "\n",
        "        else:\n",
        "            wf.data.at[index, column_name_Kd] = np.nan\n",
        "            wf.data.at[index, column_name_R2] = np.nan\n",
        "    else:\n",
        "        wf.data.at[index, column_name_Kd] = slope * (-1)\n",
        "        wf.data.at[index, column_name_R2] = r_value**2\n",
        "\n",
        "  except ValueError as er:\n",
        "      wf.data.at[index, column_name_Kd] = np.nan\n",
        "      wf.data.at[index, column_name_R2] = np.nan\n",
        "\n",
        "\n",
        "\n",
        "_wf_clear, _wf_all, _depths = analysis_kduino()"
      ],
      "metadata": {
        "id": "0nLnaJHxvpJA",
        "outputId": "b3e1ef9f-5e35-4f63-aa44-126f970d1402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KduPRO\n",
            "2025-02-05 15:00:00+00:00\n",
            "2025-02-05 15:30:00+00:00\n",
            "['CLEAR_0.70', 'CLEAR_0.70', 'CLEAR_0.70', 'CLEAR_0.70', 'CLEAR_0.70']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reindex on an axis with duplicate labels",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-9f85453eeeba>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m \u001b[0m_wf_clear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_wf_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_depths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalysis_kduino\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-9f85453eeeba>\u001b[0m in \u001b[0;36manalysis_kduino\u001b[0;34m()\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_CLEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mwf_clear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwf_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_CLEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;31m# Create columns Kd and R2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, items, like, regex, axis)\u001b[0m\n\u001b[1;32m   5796\u001b[0m                 \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5797\u001b[0m             \u001b[0;31m# error: Keywords must be strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5798\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5799\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   5376\u001b[0m         \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5377\u001b[0m     ) -> DataFrame:\n\u001b[0;32m-> 5378\u001b[0;31m         return super().reindex(\n\u001b[0m\u001b[1;32m   5379\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5380\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   5608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5609\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5610\u001b[0;31m         return self._reindex_axes(\n\u001b[0m\u001b[1;32m   5611\u001b[0m             \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5612\u001b[0m         ).__finalize__(self, method=\"reindex\")\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   5631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5632\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5633\u001b[0;31m             new_index, indexer = ax.reindex(\n\u001b[0m\u001b[1;32m   5634\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5635\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[1;32m   4427\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4428\u001b[0m                     \u001b[0;31m# GH#42568\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4429\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex on an axis with duplicate labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4430\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4431\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.- Plot linear regressions for each minute (in the PAR band)\n",
        "\n",
        "def plot_linear_regression()\n",
        "  match_CLEAR = [s for s in wf_all.data if (\"CLEAR_\" in s) and (\"QC\" not in s)]\n",
        "  # Iterate over each row of data\n",
        "  for index, _row in wf_clear.data.iterrows():\n",
        "  # CLEAR\n",
        "    row_clear = wf_clear.data.loc[index, match_CLEAR].tolist()\n",
        "    # calculate Kd from linear regression\n",
        "    slope, _intercept, r_value, _p_value, _std_err = stats.linregress(depths,\n",
        "                                                                      np.log(row_clear))\n",
        "\n",
        "    depths_row_clear = np.array(depths)\n",
        "    row_clear = np.array(np.log(row_clear))\n",
        "    # plot depths - values clear\n",
        "    plt.plot(depths_row_clear, row_clear, marker='o', linestyle=\"\")\n",
        "    plt.plot(depths_row_clear, slope*depths_row_clear + _intercept)\n",
        "    plt.xlabel(\"Depth (m)\")\n",
        "    plt.ylabel(\"ln(Light)\")\n",
        "    plt.legend([f\"$K_d$ = {np.around(slope * (-1), 3)}\",\n",
        "                f'r\\N{SUPERSCRIPT TWO} = {np.around(r_value**2, 3)}'], loc='best', markerscale=0)\n",
        "    plt.title(f\"$K_d$ at time: {index}\")\n",
        "    plt.show()\n",
        "\n",
        "  plt.close('all')\n",
        "\n",
        "plot_linear_regression()"
      ],
      "metadata": {
        "id": "-HF0eF1xGK4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.- Plot Kd Red, Green, Blue and PAR with r2 parameter\n",
        "\n",
        "# Plot Kd\n",
        "print(\"\\n\\nPlot time series Kd PAR\")\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_ylabel('$K_d$ ($m^{-1}$)')\n",
        "ax.xaxis.set_tick_params(rotation=45)\n",
        "ax.tick_params(axis='x', labelsize=8)\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
        "plt.plot(wf_clear.data['Kd'], marker='o', linestyle=\"-\")\n",
        "plt.gca().xaxis.set_major_locator(mdates.MinuteLocator(interval=10))\n",
        "plt.xlabel(\"Time (minutes)\")\n",
        "# plt.ylabel(\"Kd (m-1)\")\n",
        "ax.legend([\"Kd\"],\n",
        "                          bbox_to_anchor=(1.25, 0.95),\n",
        "                          borderaxespad=1.,\n",
        "                          ncol=1,\n",
        "                          fontsize=8,\n",
        "                          title_fontsize=10,\n",
        "                          prop={'size': 10}\n",
        "                          )\n",
        "plt.title(\"Timeseries $K_d$\")\n",
        "# plt.rcParams['figure.figsize'] = [20/2.54, 16/2.54]\n",
        "plt.show()\n",
        "\n",
        "# Plot Kd\n",
        "print(\"\\n\\nPlot time series Kd PAR with coefficient of determination r2\")\n",
        "plt.close('all')\n",
        "fig, ax = plt.subplots()\n",
        "twin1 = ax.twinx()\n",
        "twin1.set_ylabel('$r^2$')\n",
        "ax.set_ylabel('$K_d$ ($m^{-1}$)')\n",
        "ax.xaxis.set_tick_params(rotation=45)\n",
        "ax.tick_params(axis='x', labelsize=8)\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
        "p1, = ax.plot(wf_clear.data['Kd'], color=\"black\", linestyle='-',\n",
        "                              label=\"$K_d$\")\n",
        "p2, = twin1.plot(wf_clear.data['r2'], color=\"peru\", linestyle='-', label=\"$r^2$\")\n",
        "\n",
        "plt.gca().xaxis.set_major_locator(mdates.MinuteLocator(interval=10))\n",
        "ax.legend(handles=[p1, p2],\n",
        "                          bbox_to_anchor=(1.35, 0.95),\n",
        "                          borderaxespad=1.,\n",
        "                          ncol=1,\n",
        "                          fontsize=10,\n",
        "                          title_fontsize=10,\n",
        "                          prop={'size': 10}\n",
        "                          )\n",
        "ax.set_xlabel(\"Time (minutes)\")\n",
        "plt.title(\"Timeseries $K_d$\")\n",
        "# plt.rcParams['figure.figsize'] = [20/2.54, 16/2.54]\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m0ay1ik7Gqoo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}