{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kduino_Data_Analysis_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carlos-Rodero/kduino_data_analysis_notebook/blob/main/Kduino_Data_Analysis_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mooda===1.12.0\n",
        "\n",
        "import mooda as md\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import yaml\n",
        "import os\n",
        "import re\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "from scipy import stats, interpolate\n",
        "from io import StringIO\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "K3rLLm5pruii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><img alt=\"logo\" height=\"150px\" src='https://drive.google.com/uc?export=view&id=11Swg70eHalalGMv8HemoK6l7qu3XRuLC' align=\"center\" hspace=\"10px\" vspace=\"0px\"/></p>\n",
        "<h1><b>KdUINO Data Analysis Notebook</b></h1>\n",
        "\n",
        "The KdUINO Data Analysis Notebook is a Jupyter Notebook hosted by Google Colab designed to analyze data files from [KdUINO](https://monocle-h2020.eu/Sensors_and_services/KdUINO) instrumentation. Also, provide methods to generate plots and convert data files in netCDF and CSV format.</br>This Notebook works with different versions of KdUINO:\n",
        "*   KduPRO\n",
        "*   KduSTICK\n",
        "*   KduMOD Professional\n",
        "*   KduMOD Low-Cost\n",
        "</br>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Jpl8roRLyuGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><img alt=\"logo\" height=\"100px\" src='https://git.csic.es/36579996Z/kduino-data-analysis/-/raw/master/docs/img_docs/logo.png' align=\"center\" hspace=\"10px\" vspace=\"0px\"/></p>\n",
        "\n",
        "This project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 776480 ([MONOCLE](https://monocle-h2020.eu/))."
      ],
      "metadata": {
        "id": "XoBxBDf03N3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select KdUINO\n",
        "Please select your KdUINO instrument:"
      ],
      "metadata": {
        "id": "Ehyjv3wj3WvT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-_0-Zb11SgY_"
      },
      "outputs": [],
      "source": [
        "#@title Select KdUINO { run: \"auto\", display-mode: \"form\" }\n",
        "kduino = \"KduPRO\" #@param [\"KduPRO\", \"KduSTICK\", \"KduMOD Professional\", \"KduMOD Low-Cost\", \"KdUINO\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload Files\n",
        "\n",
        "Please upload the files from your KdUINO instrument:"
      ],
      "metadata": {
        "id": "TTqxEYUKvSup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "UFbx8zivrpGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration\n",
        "\n",
        "Please configure the time of the sample."
      ],
      "metadata": {
        "id": "Ky56SgiBHnK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configuration start and stop { run: \"auto\", display-mode: \"form\" }\n",
        "\n",
        "date_start = '2022-01-04' #@param {type:\"date\"}\n",
        "time_start = '10:53:00' #@param {type:\"string\"}\n",
        "date_stop = '2022-01-04' #@param {type:\"date\"}\n",
        "time_stop = '11:00:00' #@param {type:\"string\"}\n",
        "\n",
        "pre_datetime_start = date_start + \"Z\" + time_start + \"T+00:00\"\n",
        "pre_datetime_stop = date_stop + \"Z\" + time_stop + \"T+00:00\"\n",
        "\n",
        "datetime_start = datetime.fromisoformat(pre_datetime_start)\n",
        "datetime_stop = datetime.fromisoformat(pre_datetime_stop)"
      ],
      "metadata": {
        "id": "BEu3hNftIqLx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis\n",
        "\n",
        "Analysis of the KdUINO instrument."
      ],
      "metadata": {
        "id": "res-K0XUOUNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code\n",
        "\n",
        "def analysis_kduino():  \n",
        "  # Function to analyse data from KdUINO to obtain Kd  \n",
        "  if kduino == 'KduPRO':    \n",
        "    print(\"KduPRO\")    \n",
        "    print(datetime_start)    \n",
        "    print(datetime_stop)    \n",
        "    \n",
        "    # Definitions for regular expression paterns    \n",
        "    start_string_metadata = r\"METADATA\"    \n",
        "    stop_string_metadata = r\"DATA\"    \n",
        "    start_string_data = r\"\\bDATA\"    \n",
        "    stop_string_data = r\"METADATA\"    \n",
        "    last_start_string_data = r\"\\bDATA\"    \n",
        "    end_string_data = r'$(?![\\r\\n])'\n",
        "    \n",
        "    metadata_patron = re.compile(r'{}(?P<length>)\\s*(?P<table>[\\s\\S]*?){}'.format(\n",
        "        start_string_metadata, stop_string_metadata))    \n",
        "    data_patron = re.compile(r'{}(?P<length>)\\s*(?P<table>[\\s\\S]*?){}'.format(        \n",
        "        start_string_data, stop_string_data))        \n",
        "    last_data_patron = re.compile(r'{}(?P<length>)\\s*(?P<table>[\\s\\S]*?){}'.format(        \n",
        "        last_start_string_data, end_string_data))\n",
        "    \n",
        "    selected_info = \"\"    \n",
        "    metadata_list = []    \n",
        "    metadata = {}    \n",
        "    data_list = []    \n",
        "    kdupro_list = []        \n",
        "    \n",
        "    for k, v in uploaded.items():      \n",
        "      # print(k)      \n",
        "      # print(v)      \n",
        "      \n",
        "      with open(k) as reader:        \n",
        "        content = reader.read()        \n",
        "        # print(content)        \n",
        "        \n",
        "        # Regular expression to find the metadata patron        \n",
        "        for m in re.finditer(metadata_patron, content):          \n",
        "          selected_info = m.group('table')          \n",
        "          metadata = {}          \n",
        "          lines = selected_info.splitlines()          \n",
        "          for line in lines:            \n",
        "            key = line.split(\":\")[0]            \n",
        "            if line.count(\":\") > 1:              \n",
        "              date_splitted = (line.rsplit(\":\")[-3:])              \n",
        "              date_splitted = \" \".join(date_splitted)              \n",
        "              value = date_splitted              \n",
        "              metadata[key] = value            \n",
        "            else:              \n",
        "              value = line.split(\":\")[1]              \n",
        "              metadata[key] = value.strip()          \n",
        "            \n",
        "          metadata_list.append(metadata)        \n",
        "        \n",
        "        # Regular expression to find the data patron        \n",
        "        for d in re.finditer(data_patron, content):          \n",
        "          selected_info_data = d.group('table')          \n",
        "          data = StringIO(selected_info_data)          \n",
        "          df = pd.read_csv(data, skipinitialspace=True, skiprows=1, header=None,                           \n",
        "                           parse_dates={'TIME': [0]},                           \n",
        "                           delimiter=' ', engine='python').set_index('TIME')          \n",
        "          data_list.append(df)        \n",
        "        \n",
        "        for m in re.finditer(last_data_patron, content):          \n",
        "          selected_info_data = m.group('table')          \n",
        "          index_last_data = selected_info_data.rfind('DATA')          \n",
        "          selected_info_last_data = selected_info_data[index_last_data:]          \n",
        "          data = StringIO(selected_info_last_data)          \n",
        "          df = pd.read_csv(data, skipinitialspace=True, skiprows=2, header=None,                           \n",
        "                           parse_dates={'TIME': [0, 1]},                           \n",
        "                           delimiter=' ', engine='python').set_index('TIME')          \n",
        "          data_list.append(df)        \n",
        "          \n",
        "    for index, df in enumerate(data_list):      \n",
        "      if datetime_start in df.index or datetime_stop in df.index:        \n",
        "        kdupro_list.append(index)    \n",
        "            \n",
        "    # process the files we have selected    \n",
        "    def create_wf():      \n",
        "      df = data_list[index]      \n",
        "      metadata = metadata_list[index]            \n",
        "      df.columns = range(df.shape[1])      \n",
        "      \n",
        "      # Delete unused columns      \n",
        "      if len(df.columns) > 4:          \n",
        "        df_copy = df.copy()          \n",
        "        ncol = len(df.columns)          \n",
        "        x = range(4, ncol)          \n",
        "        df = df.drop(x, axis=1)      \n",
        "        \n",
        "      df.columns = range(df.shape[1])      \n",
        "        \n",
        "      # Creation of WaterFrame      \n",
        "      wf = md.WaterFrame()      \n",
        "      \n",
        "      # Copy metadata to waterframe      \n",
        "      wf.metadata = metadata      \n",
        "      depth = wf.metadata[\"depth\"]      \n",
        "      \n",
        "      # Set name of parameters      \n",
        "      param_red = f'RED_{depth}'      \n",
        "      param_green = f'GREEN_{depth}'      \n",
        "      param_blue = f'BLUE_{depth}'      \n",
        "      param_clear = f'CLEAR_{depth}'      \n",
        "      \n",
        "      # Set name of QC parameters      \n",
        "      param_red_qc = f'RED_{depth}_QC'      \n",
        "      param_green_qc = f'GREEN_{depth}_QC'      \n",
        "      param_blue_qc = f'BLUE_{depth}_QC'      \n",
        "      param_clear_qc = f'CLEAR_{depth}_QC'      \n",
        "      \n",
        "      # Init data of waterframe      \n",
        "      wf.data[param_red] = df[0]      \n",
        "      wf.data[param_green] = df[1]      \n",
        "      wf.data[param_blue] = df[2]      \n",
        "      wf.data[param_clear] = df[3]      \n",
        "      \n",
        "      # Create vocabulary      \n",
        "      wf.vocabulary[param_red] = {'units': \"counts\"}     \n",
        "      wf.vocabulary[param_green] = {'units': \"counts\"}      \n",
        "      wf.vocabulary[param_blue] = {'units': \"counts\"}      \n",
        "      wf.vocabulary[param_clear] = {'units': \"counts\"}      \n",
        "      \n",
        "      # Resample to seconds      \n",
        "      wf.resample('S')      \n",
        "      \n",
        "      # Delete last index because it is a minute that we are not going to use      \n",
        "      wf.data.drop(wf.data.tail(1).index, inplace=True)      \n",
        "      # Extract data of the dataframe df. Put all counts in the proper column      \n",
        "      red_list = []      \n",
        "      green_list = []      \n",
        "      blue_list = []      \n",
        "      clear_list = []      \n",
        "      \n",
        "      for j in range(len(df_copy.index)-1):        \n",
        "        for i in range(len(df_copy.columns)):          \n",
        "          if i % 4 == 0:            \n",
        "            red_list.append(df_copy[i][j])            \n",
        "            green_list.append(df_copy[i+1].iloc[j])            \n",
        "            blue_list.append(df_copy[i+2].iloc[j])            \n",
        "            clear_list.append(df_copy[i+3].iloc[j])      \n",
        "      red_array = np.array(red_list)      \n",
        "      green_array = np.array(green_list)      \n",
        "      blue_array = np.array(blue_list)      \n",
        "      clear_array = np.array(clear_list)      \n",
        "      \n",
        "      wf.data[param_red] = red_array      \n",
        "      wf.data[param_green] = green_array      \n",
        "      wf.data[param_blue] = blue_array      \n",
        "      wf.data[param_clear] = clear_array      \n",
        "      \n",
        "      # Init waterframe QC data      \n",
        "      wf.data[param_red_qc] = 0      \n",
        "      wf.data[param_green_qc] = 0      \n",
        "      wf.data[param_blue_qc] = 0      \n",
        "      wf.data[param_clear_qc] = 0      \n",
        "      \n",
        "      return wf    \n",
        "      \n",
        "    def merge_metadata(dict1, dict2):      \n",
        "      # Merge dictionaries      \n",
        "      dict3 = {**dict1, **dict2}      \n",
        "      # Iterate over items in new dictionary      \n",
        "      for key, value in dict3.items():          \n",
        "        # If keys are in both dictionaries          \n",
        "        if key in dict1 and key in dict2:              \n",
        "          # If dictionary contains list of elements              \n",
        "          if isinstance(value, list):                  \n",
        "            # If values of new dict and values from parameter dict are different,                  \n",
        "            # and not included in the new dict                  \n",
        "            if (dict1[key] not in value) and (set(dict1[key]) != set(value)):                      \n",
        "              dict3[key].append(dict1[key])                  \n",
        "            elif (dict2[key] not in value) and (set(dict2[key]) != set(value)):                      \n",
        "              dict3[key].append(dict2[key])              \n",
        "        \n",
        "        # If dictionary not contains list of elements              \n",
        "        else:                  \n",
        "          if value != dict1[key]:                      \n",
        "            dict3[key] = [value, dict1[key]]                  \n",
        "          elif value != dict2[key]:                      \n",
        "            dict3[key] = [value, dict2[key]]      \n",
        "        \n",
        "        return dict3    \n",
        "        \n",
        "    wf_list = []        \n",
        "    for index in kdupro_list:      \n",
        "      wf = create_wf()      \n",
        "      wf_list.append(wf)    \n",
        "      \n",
        "    # Declare lists    \n",
        "    names = []    \n",
        "    depths = []    \n",
        "    # Create unique waterframe    \n",
        "    wf_all = md.WaterFrame()    \n",
        "    # Concat all waterframes    \n",
        "    for index, wf in enumerate(wf_list):      \n",
        "      if index == 0:        \n",
        "        wf_all = wf.copy()      \n",
        "      else:        \n",
        "        # Concat data        \n",
        "        wf_all.data = pd.concat([wf_all.data, wf.data], axis=1)        \n",
        "        # Add metadata        \n",
        "        wf_all.metadata = merge_metadata(wf.metadata, wf_all.metadata)        \n",
        "        # Add vocabulary        \n",
        "        for param in wf.parameters:            \n",
        "          wf_all.vocabulary[param] = wf.vocabulary[param]    \n",
        "    \n",
        "    # Append names and depths to each list    \n",
        "    for wf in wf_list:        \n",
        "      if wf is None:            \n",
        "        pass        \n",
        "      else:            \n",
        "        name = wf.metadata[\"name\"]            \n",
        "        names.append(name)            \n",
        "        depth = wf.metadata[\"depth\"]            \n",
        "        depths.append(depth)        \n",
        "    \n",
        "    # Slice time    \n",
        "    mask = (        \n",
        "        wf_all.data.index >= datetime_start) & (            \n",
        "            wf_all.data.index <= datetime_stop)    \n",
        "    wf_all.data = wf_all.data.loc[mask]    \n",
        "    \n",
        "    # Resample time    \n",
        "    wf_all.resample(\"T\")    \n",
        "    \n",
        "    # Convert depths list elements to float, and save it as a numpy array    \n",
        "    depths = np.array(list(map(float, depths)))    \n",
        "    \n",
        "    # Save CLEAR data in one new waterframe    \n",
        "    wf_clear = md.WaterFrame()    \n",
        "    wf_clear.metadata = wf_all.metadata    \n",
        "    wf_clear.vocabulary = wf_all.vocabulary    \n",
        "    \n",
        "    match_CLEAR = [s for s in wf_all.data if (\"CLEAR\" in s) and (\"QC\" not in s)]    \n",
        "    wf_clear.data = wf_all.data.filter(match_CLEAR)\n",
        "    \n",
        "    # Calculate Kd in new column    \n",
        "    kd_list = []    \n",
        "    r2_list = []   \n",
        "    wf_clear.data['Kd'] = 0    \n",
        "    wf_clear.data['r2'] = 0    \n",
        "    for index, _row in wf_clear.data.iterrows():      \n",
        "      # CLEAR      \n",
        "      row_clear = wf_clear.data.loc[index, match_CLEAR].tolist()      \n",
        "      # calculate Kd from linear regression      \n",
        "      slope, _intercept, r_value, _p_value, _std_err = stats.linregress(depths,                                                                        \n",
        "                                                                        np.log(row_clear))      \n",
        "      kd_list.append(slope * (-1))      \n",
        "      r2_list.append(r_value**2)          \n",
        "    \n",
        "      depths_row_clear = np.array(depths)      \n",
        "      row_clear = np.array(np.log(row_clear))      \n",
        "      # plot depths - values clear      \n",
        "      plt.plot(depths_row_clear, row_clear, marker='o', linestyle=\"\")      \n",
        "      plt.plot(depths_row_clear, slope*depths_row_clear + _intercept)      \n",
        "      plt.xlabel(\"Depth (m)\")      \n",
        "      plt.ylabel(\"ln(Light)\")      \n",
        "      plt.legend([f\"Kd = {np.around(slope * (-1), 3)}\",                  \n",
        "                  f'r\\N{SUPERSCRIPT TWO} = {np.around(r_value**2, 3)}'], loc='best', markerscale=0)      \n",
        "      plt.title(f\"Kd at time: {index}\")      \n",
        "      plt.show()    \n",
        "    \n",
        "    plt.close('all')        \n",
        "    \n",
        "    wf_clear.data['Kd'] = kd_list    \n",
        "    wf_clear.data['r2'] = r2_list        \n",
        "    print(wf_clear.data)    \n",
        "    print(\"\")        \n",
        "    avgKd = wf_clear.data.loc[wf_clear.data['r2'] > 0.9, 'Kd'].mean()    \n",
        "    print(\"Average Kd for samples with r2 > 0.9: {}\".format(np.around(avgKd, 3)))    \n",
        "    \n",
        "    # Plot Kd    \n",
        "    plt.plot(wf_clear.data.index.strftime('%H:%M'), wf_clear.data['Kd'], marker='o', linestyle=\"-\")    \n",
        "    plt.xlabel(\"Time (minutes)\")    \n",
        "    plt.ylabel(\"Kd (m-1)\")    \n",
        "    plt.legend(\"Kd\")    \n",
        "    plt.title(\"Timeseries Kd\")    \n",
        "    plt.show()  \n",
        "  \n",
        "  else:    \n",
        "    print(\"KdUINO instrument not configured well.\")\n",
        "    \n",
        "analysis_kduino()"
      ],
      "metadata": {
        "id": "0nLnaJHxvpJA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}